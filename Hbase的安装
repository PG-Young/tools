		要注意集群时间同步ClockOutOfSyncException异
1、上传hbase-1.3.1-bin.tar.gz到/opt/software 解压到/opt/module
2、重命名，修改/opt/module/hbase/conf配置文件
	vim  hbase-env.sh
		export JAVA_HOME=/opt/module/jdk1.8.0_144
		export HBASE_MANAGES_ZK=false
3、修改hbase-site.xml
					<configuration>
						<property>     
							<name>hbase.rootdir</name>     
							<value>hdfs://hadoop101:9000/hbase</value>               
						</property>

						<property>   
							<name>hbase.cluster.distributed</name>
							<value>true</value>
						</property>

					   <!-- 0.98后的新变动，之前版本没有.port,默认端口为60000(可省略) -->
						<property>
							<name>hbase.master.port</name>
							<value>16000</value>
						</property>

						<property>
							<name>hbase.zookeeper.quorum</name>
						      <value>hadoop101,hadoop102,hadoop103</value>
						</property>
					    
					<!-- 参照zk的zoo.cfg文件中的dataDir值 -->
						<property>   
							<name>hbase.zookeeper.property.dataDir</name>
						    <value>/opt/module/zookeeper-3.4.10/zkData</value>
						</property>
					</configuration>
4、软连接hadoop配置文件到HBase
		[atguigu@hadoop102 module]$ ln -s /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml /opt/module/hbase/conf/core-site.xml
		[atguigu@hadoop102 module]$ ln -s /opt/module/hadoop-2.7.2/etc/hadoop/hdfs-site.xml /opt/module/hbase/conf/hdfs-site.xml

修改regionservers文件
hadoop101
hadoop102
hadoop103


5.发送HBase到其他节点  xsync hbase/ 
6 HBase服务启动1  
				[atguigu@hadoop102 hbase]$ bin/hbase-daemon.sh start master
				[atguigu@hadoop102 hbase]$ bin/hbase-daemon.sh start regionserver
启动方式2	
				[atguigu@hadoop102 hbase]$ bin/start-hbase.sh	 
				bin/stop-hbase.sh
7、hbase的页面http://hadoop102:16010 

案例一：Hbase-MapReduce
	bin/hbase mapredcp
	export HBASE_HOME=/opt/module/hbase
	$ export HADOOP_HOME=/opt/module/hadoop-2.7.2
	$ export HADOOP_CLASSPATH=`${HBASE_HOME}/bin/hbase mapredcp`
（2）永久生效：在/etc/profile配置
	export HBASE_HOME=/opt/module/hbase
	export HADOOP_HOME=/opt/module/hadoop-2.7.2
	并在hadoop-env.sh中配置：（注意：在for循环之后配）
	export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/opt/module/hbase/lib/*
3）在HDFS中创建input_fruit文件夹并上传fruit.tsv文件
$ /opt/module/hadoop-2.7.2/bin/hdfs dfs -mkdir /input_fruit/
$ /opt/module/hadoop-2.7.2/bin/hdfs dfs -put fruit.tsv /input_fruit/

4）执行MapReduce到HBase的fruit表中
$ /opt/module/hadoop-2.7.2/bin/yarn jar lib/hbase-server-1.3.1.jar importtsv \
-Dimporttsv.columns=HBASE_ROW_KEY,info:name,info:color fruit \
hdfs://hadoop102:9000/input_fruit
